digraph {
	graph [size="265.95,265.95"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140639375737984 [label="
 ()" fillcolor=darkolivegreen1]
	140639375791152 [label=MeanBackward0]
	140639375791440 -> 140639375791152
	140639375791440 [label=AddmmBackward]
	140639375791392 -> 140639375791440
	140639512324864 [label="head.bias
 (1000)" fillcolor=lightblue]
	140639512324864 -> 140639375791392
	140639375791392 [label=AccumulateGrad]
	140639375791344 -> 140639375791440
	140639375791344 [label=MeanBackward1]
	140639375791488 -> 140639375791344
	140639375791488 [label=NativeLayerNormBackward]
	140639375791680 -> 140639375791488
	140639375791680 [label=AddBackward0]
	140639375791872 -> 140639375791680
	140639375791872 [label=TransposeBackward0]
	140639375792016 -> 140639375791872
	140639375792016 [label=SqueezeBackward1]
	140639375792112 -> 140639375792016
	140639375792112 [label=ThnnConvDepthwise2DBackward]
	140639375792208 -> 140639375792112
	140639375792208 [label=UnsqueezeBackward0]
	140639375792352 -> 140639375792208
	140639375792352 [label=CopyBackwards]
	140639375792448 -> 140639375792352
	140639375792448 [label=TransposeBackward0]
	140639375792544 -> 140639375792448
	140639375792544 [label=NativeLayerNormBackward]
	140639375792640 -> 140639375792544
	140639375792640 [label=AddBackward0]
	140639375792832 -> 140639375792640
	140639375792832 [label=AddBackward0]
	140639375792976 -> 140639375792832
	140639375792976 [label=TransposeBackward0]
	140639375793120 -> 140639375792976
	140639375793120 [label=SqueezeBackward1]
	140639375793216 -> 140639375793120
	140639375793216 [label=ThnnConvDepthwise2DBackward]
	140639375793360 -> 140639375793216
	140639375793360 [label=UnsqueezeBackward0]
	140639375793504 -> 140639375793360
	140639375793504 [label=CopyBackwards]
	140639375793648 -> 140639375793504
	140639375793648 [label=TransposeBackward0]
	140639375793744 -> 140639375793648
	140639375793744 [label=NativeLayerNormBackward]
	140639375793888 -> 140639375793744
	140639375793888 [label=AddBackward0]
	140639375794080 -> 140639375793888
	140639375794080 [label=TransposeBackward0]
	140639375794128 -> 140639375794080
	140639375794128 [label=ViewBackward]
	140639248331008 -> 140639375794128
	140639248331008 [label=AddBackward0]
	140639248331152 -> 140639248331008
	140639248331152 [label=CudnnConvolutionBackward]
	140639248331296 -> 140639248331152
	140639248331296 [label=AvgPool2DBackward]
	140639248331440 -> 140639248331296
	140639248331440 [label=AddBackward0]
	140639248331584 -> 140639248331440
	140639248331584 [label=CudnnConvolutionBackward]
	140639248331728 -> 140639248331584
	140639248331728 [label=AvgPool2DBackward]
	140639248331872 -> 140639248331728
	140639248331872 [label=AddBackward0]
	140639248332016 -> 140639248331872
	140639248332016 [label=CudnnConvolutionBackward]
	140639248332160 -> 140639248332016
	140639248332160 [label=AvgPool2DBackward]
	140639248332304 -> 140639248332160
	140639248332304 [label=MaxPool2DWithIndicesBackward]
	140639248332448 -> 140639248332304
	140639248332448 [label=ReluBackward0]
	140639248332592 -> 140639248332448
	140639248332592 [label=CudnnConvolutionBackward]
	140639248332736 -> 140639248332592
	140639248332736 [label=MaxPool2DWithIndicesBackward]
	140639248332880 -> 140639248332736
	140639248332880 [label=ReluBackward0]
	140639248333024 -> 140639248332880
	140639248333024 [label=CudnnConvolutionBackward]
	140639248333168 -> 140639248333024
	140639529145344 [label="tokenizer.conv_layers.0.0.weight
 (64, 3, 3, 3)" fillcolor=lightblue]
	140639529145344 -> 140639248333168
	140639248333168 [label=AccumulateGrad]
	140639248332688 -> 140639248332592
	140639529145984 [label="tokenizer.conv_layers.1.0.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	140639529145984 -> 140639248332688
	140639248332688 [label=AccumulateGrad]
	140639248332112 -> 140639248332016
	140639529155776 [label="stages.0.downsample_shortcut.1.weight
 (128, 128, 1, 1)" fillcolor=lightblue]
	140639529155776 -> 140639248332112
	140639248332112 [label=AccumulateGrad]
	140639248331968 -> 140639248331872
	140639248331968 [label=ViewBackward]
	140639248332400 -> 140639248331968
	140639248332400 [label=TransposeBackward0]
	140639248332640 -> 140639248332400
	140639248332640 [label=UnsafeViewBackward]
	140639248332976 -> 140639248332640
	140639248332976 [label=MmBackward]
	140639248333312 -> 140639248332976
	140639248333312 [label=ViewBackward]
	140639248333360 -> 140639248333312
	140639248333360 [label=NativeLayerNormBackward]
	140639248333456 -> 140639248333360
	140639248333456 [label=ViewBackward]
	140639248333648 -> 140639248333456
	140639248333648 [label=CatBackward]
	140639248333744 -> 140639248333648
	140639248333744 [label=SliceBackward]
	140639248333984 -> 140639248333744
	140639248333984 [label=SliceBackward]
	140639248334080 -> 140639248333984
	140639248334080 [label=SliceBackward]
	140639248334224 -> 140639248334080
	140639248334224 [label=SliceBackward]
	140639248334368 -> 140639248334224
	140639248334368 [label=ViewBackward]
	140639248334512 -> 140639248334368
	140639248334512 [label=AddBackward0]
	140639248334656 -> 140639248334512
	140639248334656 [label=TransposeBackward0]
	140639248334800 -> 140639248334656
	140639248334800 [label=SqueezeBackward1]
	140639248355488 -> 140639248334800
	140639248355488 [label=ThnnConvDepthwise2DBackward]
	140639248355632 -> 140639248355488
	140639248355632 [label=UnsqueezeBackward0]
	140639248355776 -> 140639248355632
	140639248355776 [label=CopyBackwards]
	140639248355920 -> 140639248355776
	140639248355920 [label=TransposeBackward0]
	140639248356016 -> 140639248355920
	140639248356016 [label=NativeLayerNormBackward]
	140639248356160 -> 140639248356016
	140639248356160 [label=AddBackward0]
	140639248356352 -> 140639248356160
	140639248356352 [label=AddBackward0]
	140639248356496 -> 140639248356352
	140639248356496 [label=TransposeBackward0]
	140639248356640 -> 140639248356496
	140639248356640 [label=SqueezeBackward1]
	140639248356784 -> 140639248356640
	140639248356784 [label=ThnnConvDepthwise2DBackward]
	140639248356928 -> 140639248356784
	140639248356928 [label=UnsqueezeBackward0]
	140639248357072 -> 140639248356928
	140639248357072 [label=CopyBackwards]
	140639248357216 -> 140639248357072
	140639248357216 [label=TransposeBackward0]
	140639248357312 -> 140639248357216
	140639248357312 [label=NativeLayerNormBackward]
	140639248357456 -> 140639248357312
	140639248357456 [label=AddBackward0]
	140639248357648 -> 140639248357456
	140639248357648 [label=TransposeBackward0]
	140639248357792 -> 140639248357648
	140639248357792 [label=ViewBackward]
	140639248332304 -> 140639248357792
	140639248357600 -> 140639248357456
	140639248357600 [label=TransposeBackward0]
	140639248357840 -> 140639248357600
	140639248357840 [label=AddBackward0]
	140639248358032 -> 140639248357840
	140639248358032 [label=UnsafeViewBackward]
	140639248358176 -> 140639248358032
	140639248358176 [label=MmBackward]
	140639248358272 -> 140639248358176
	140639248358272 [label=ViewBackward]
	140639248358416 -> 140639248358272
	140639248358416 [label=ViewBackward]
	140639248358560 -> 140639248358416
	140639248358560 [label=CopyBackwards]
	140639248358704 -> 140639248358560
	140639248358704 [label=TransposeBackward0]
	140639248358800 -> 140639248358704
	140639248358800 [label=ViewBackward]
	140639248358944 -> 140639248358800
	140639248358944 [label=GeluBackward]
	140639248359088 -> 140639248358944
	140639248359088 [label=AddBackward0]
	140639248359232 -> 140639248359088
	140639248359232 [label=UnsafeViewBackward]
	140639248359376 -> 140639248359232
	140639248359376 [label=MmBackward]
	140639248380064 -> 140639248359376
	140639248380064 [label=ViewBackward]
	140639248380208 -> 140639248380064
	140639248380208 [label=CopyBackwards]
	140639248380352 -> 140639248380208
	140639248380352 [label=TransposeBackward0]
	140639248380448 -> 140639248380352
	140639248380448 [label=NativeLayerNormBackward]
	140639248357648 -> 140639248380448
	140639248380592 -> 140639248380448
	140639529147008 [label="stages.0.blocks.0.norm1.weight
 (128)" fillcolor=lightblue]
	140639529147008 -> 140639248380592
	140639248380592 [label=AccumulateGrad]
	140639248380544 -> 140639248380448
	140639529147200 [label="stages.0.blocks.0.norm1.bias
 (128)" fillcolor=lightblue]
	140639529147200 -> 140639248380544
	140639248380544 [label=AccumulateGrad]
	140639248380016 -> 140639248359376
	140639248380016 [label=TBackward]
	140639248380400 -> 140639248380016
	140639529147328 [label="stages.0.blocks.0.token_mlp.fc1.weight
 (128, 3136)" fillcolor=lightblue]
	140639529147328 -> 140639248380400
	140639248380400 [label=AccumulateGrad]
	140639248359184 -> 140639248359088
	140639529147584 [label="stages.0.blocks.0.token_mlp.fc1.bias
 (128)" fillcolor=lightblue]
	140639529147584 -> 140639248359184
	140639248359184 [label=AccumulateGrad]
	140639248358224 -> 140639248358176
	140639248358224 [label=TBackward]
	140639248358656 -> 140639248358224
	140639529147648 [label="stages.0.blocks.0.token_mlp.fc2.weight
 (3136, 128)" fillcolor=lightblue]
	140639529147648 -> 140639248358656
	140639248358656 [label=AccumulateGrad]
	140639248357984 -> 140639248357840
	140639529147840 [label="stages.0.blocks.0.token_mlp.fc2.bias
 (3136)" fillcolor=lightblue]
	140639529147840 -> 140639248357984
	140639248357984 [label=AccumulateGrad]
	140639248357408 -> 140639248357312
	140639529147968 [label="stages.0.blocks.0.norm2.weight
 (128)" fillcolor=lightblue]
	140639529147968 -> 140639248357408
	140639248357408 [label=AccumulateGrad]
	140639248357360 -> 140639248357312
	140639529148160 [label="stages.0.blocks.0.norm2.bias
 (128)" fillcolor=lightblue]
	140639529148160 -> 140639248357360
	140639248357360 [label=AccumulateGrad]
	140639248356880 -> 140639248356784
	140639248356880 [label=UnsqueezeBackward0]
	140639248357264 -> 140639248356880
	140639529148352 [label="stages.0.blocks.0.connect.weight
 (128, 1, 3)" fillcolor=lightblue]
	140639529148352 -> 140639248357264
	140639248357264 [label=AccumulateGrad]
	140639248356448 -> 140639248356352
	140639248356448 [label=AddBackward0]
	140639248356832 -> 140639248356448
	140639248356832 [label=UnsafeViewBackward]
	140639248357504 -> 140639248356832
	140639248357504 [label=MmBackward]
	140639248357936 -> 140639248357504
	140639248357936 [label=ViewBackward]
	140639248358080 -> 140639248357936
	140639248358080 [label=ViewBackward]
	140639248358896 -> 140639248358080
	140639248358896 [label=CopyBackwards]
	140639248358368 -> 140639248358896
	140639248358368 [label=TransposeBackward0]
	140639248359136 -> 140639248358368
	140639248359136 [label=ViewBackward]
	140639248359328 -> 140639248359136
	140639248359328 [label=GeluBackward]
	140639248380688 -> 140639248359328
	140639248380688 [label=AddBackward0]
	140639248380160 -> 140639248380688
	140639248380160 [label=UnsafeViewBackward]
	140639248380832 -> 140639248380160
	140639248380832 [label=MmBackward]
	140639248380928 -> 140639248380832
	140639248380928 [label=ViewBackward]
	140639248381072 -> 140639248380928
	140639248381072 [label=NativeLayerNormBackward]
	140639248356496 -> 140639248381072
	140639248357408 -> 140639248381072
	140639248357360 -> 140639248381072
	140639248380880 -> 140639248380832
	140639248380880 [label=TBackward]
	140639248381120 -> 140639248380880
	140639529153728 [label="stages.0.blocks.0.channel_mlp.fc1.weight
 (256, 128)" fillcolor=lightblue]
	140639529153728 -> 140639248381120
	140639248381120 [label=AccumulateGrad]
	140639248380496 -> 140639248380688
	140639529154496 [label="stages.0.blocks.0.channel_mlp.fc1.bias
 (256)" fillcolor=lightblue]
	140639529154496 -> 140639248380496
	140639248380496 [label=AccumulateGrad]
	140639248357024 -> 140639248357504
	140639248357024 [label=TBackward]
	140639248358752 -> 140639248357024
	140639529155136 [label="stages.0.blocks.0.channel_mlp.fc2.weight
 (128, 256)" fillcolor=lightblue]
	140639529155136 -> 140639248358752
	140639248358752 [label=AccumulateGrad]
	140639248356736 -> 140639248356448
	140639529155840 [label="stages.0.blocks.0.channel_mlp.fc2.bias
 (128)" fillcolor=lightblue]
	140639529155840 -> 140639248356736
	140639248356736 [label=AccumulateGrad]
	140639248356304 -> 140639248356160
	140639248356304 [label=MulBackward0]
	140639248358128 -> 140639248356304
	140639248358128 [label=DivBackward0]
	140639248357552 -> 140639248358128
	140639248357552 [label=TransposeBackward0]
	140639248359040 -> 140639248357552
	140639248359040 [label=AddBackward0]
	140639248358512 -> 140639248359040
	140639248358512 [label=UnsafeViewBackward]
	140639248380736 -> 140639248358512
	140639248380736 [label=MmBackward]
	140639248381216 -> 140639248380736
	140639248381216 [label=ViewBackward]
	140639248381264 -> 140639248381216
	140639248381264 [label=ViewBackward]
	140639248381360 -> 140639248381264
	140639248381360 [label=CopyBackwards]
	140639248381456 -> 140639248381360
	140639248381456 [label=TransposeBackward0]
	140639248381552 -> 140639248381456
	140639248381552 [label=ViewBackward]
	140639248381648 -> 140639248381552
	140639248381648 [label=GeluBackward]
	140639248381744 -> 140639248381648
	140639248381744 [label=AddBackward0]
	140639248381840 -> 140639248381744
	140639248381840 [label=UnsafeViewBackward]
	140639248381984 -> 140639248381840
	140639248381984 [label=MmBackward]
	140639248382080 -> 140639248381984
	140639248382080 [label=ViewBackward]
	140639248382224 -> 140639248382080
	140639248382224 [label=CopyBackwards]
	140639248382320 -> 140639248382224
	140639248382320 [label=TransposeBackward0]
	140639248382416 -> 140639248382320
	140639248382416 [label=NativeLayerNormBackward]
	140639248356352 -> 140639248382416
	140639248382512 -> 140639248382416
	140639556583360 [label="stages.0.blocks.1.norm1.weight
 (128)" fillcolor=lightblue]
	140639556583360 -> 140639248382512
	140639248382512 [label=AccumulateGrad]
	140639248382464 -> 140639248382416
	140639529156160 [label="stages.0.blocks.1.norm1.bias
 (128)" fillcolor=lightblue]
	140639529156160 -> 140639248382464
	140639248382464 [label=AccumulateGrad]
	140639248382032 -> 140639248381984
	140639248382032 [label=TBackward]
	140639248382368 -> 140639248382032
	140639529152576 [label="stages.0.blocks.1.token_mlp.fc1.weight
 (128, 3136)" fillcolor=lightblue]
	140639529152576 -> 140639248382368
	140639248382368 [label=AccumulateGrad]
	140639248381792 -> 140639248381744
	140639529152832 [label="stages.0.blocks.1.token_mlp.fc1.bias
 (128)" fillcolor=lightblue]
	140639529152832 -> 140639248381792
	140639248381792 [label=AccumulateGrad]
	140639248380784 -> 140639248380736
	140639248380784 [label=TBackward]
	140639248381408 -> 140639248380784
	140639529153088 [label="stages.0.blocks.1.token_mlp.fc2.weight
 (3136, 128)" fillcolor=lightblue]
	140639529153088 -> 140639248381408
	140639248381408 [label=AccumulateGrad]
	140639248356400 -> 140639248359040
	140639529153280 [label="stages.0.blocks.1.token_mlp.fc2.bias
 (3136)" fillcolor=lightblue]
	140639529153280 -> 140639248356400
	140639248356400 [label=AccumulateGrad]
	140639248356112 -> 140639248356016
	140639529153408 [label="stages.0.blocks.1.norm2.weight
 (128)" fillcolor=lightblue]
	140639529153408 -> 140639248356112
	140639248356112 [label=AccumulateGrad]
	140639248356064 -> 140639248356016
	140639529153664 [label="stages.0.blocks.1.norm2.bias
 (128)" fillcolor=lightblue]
	140639529153664 -> 140639248356064
	140639248356064 [label=AccumulateGrad]
	140639248355584 -> 140639248355488
	140639248355584 [label=UnsqueezeBackward0]
	140639248355968 -> 140639248355584
	140639529153984 [label="stages.0.blocks.1.connect.weight
 (128, 1, 3)" fillcolor=lightblue]
	140639529153984 -> 140639248355968
	140639248355968 [label=AccumulateGrad]
	140639248334608 -> 140639248334512
	140639248334608 [label=MulBackward0]
	140639248334752 -> 140639248334608
	140639248334752 [label=DivBackward0]
	140639248356256 -> 140639248334752
	140639248356256 [label=AddBackward0]
	140639248355728 -> 140639248356256
	140639248355728 [label=UnsafeViewBackward]
	140639248357744 -> 140639248355728
	140639248357744 [label=MmBackward]
	140639248356592 -> 140639248357744
	140639248356592 [label=ViewBackward]
	140639248381600 -> 140639248356592
	140639248381600 [label=ViewBackward]
	140639248381024 -> 140639248381600
	140639248381024 [label=CopyBackwards]
	140639248380976 -> 140639248381024
	140639248380976 [label=TransposeBackward0]
	140639248381888 -> 140639248380976
	140639248381888 [label=ViewBackward]
	140639248382560 -> 140639248381888
	140639248382560 [label=GeluBackward]
	140639248382176 -> 140639248382560
	140639248382176 [label=AddBackward0]
	140639248382656 -> 140639248382176
	140639248382656 [label=UnsafeViewBackward]
	140639248382800 -> 140639248382656
	140639248382800 [label=MmBackward]
	140639248382896 -> 140639248382800
	140639248382896 [label=ViewBackward]
	140639248383040 -> 140639248382896
	140639248383040 [label=NativeLayerNormBackward]
	140639248334656 -> 140639248383040
	140639248356112 -> 140639248383040
	140639248356064 -> 140639248383040
	140639248382848 -> 140639248382800
	140639248382848 [label=TBackward]
	140639248383088 -> 140639248382848
	140639529154432 [label="stages.0.blocks.1.channel_mlp.fc1.weight
 (256, 128)" fillcolor=lightblue]
	140639529154432 -> 140639248383088
	140639248383088 [label=AccumulateGrad]
	140639248382608 -> 140639248382176
	140639529154688 [label="stages.0.blocks.1.channel_mlp.fc1.bias
 (256)" fillcolor=lightblue]
	140639529154688 -> 140639248382608
	140639248382608 [label=AccumulateGrad]
	140639248381312 -> 140639248357744
	140639248381312 [label=TBackward]
	140639248381696 -> 140639248381312
	140639529154944 [label="stages.0.blocks.1.channel_mlp.fc2.weight
 (128, 256)" fillcolor=lightblue]
	140639529154944 -> 140639248381696
	140639248381696 [label=AccumulateGrad]
	140639248356208 -> 140639248356256
	140639529155200 [label="stages.0.blocks.1.channel_mlp.fc2.bias
 (128)" fillcolor=lightblue]
	140639529155200 -> 140639248356208
	140639248356208 [label=AccumulateGrad]
	140639248333696 -> 140639248333648
	140639248333696 [label=SliceBackward]
	140639248334176 -> 140639248333696
	140639248334176 [label=SliceBackward]
	140639248334464 -> 140639248334176
	140639248334464 [label=SliceBackward]
	140639248334560 -> 140639248334464
	140639248334560 [label=SliceBackward]
	140639248334368 -> 140639248334560
	140639248333552 -> 140639248333648
	140639248333552 [label=SliceBackward]
	140639248333936 -> 140639248333552
	140639248333936 [label=SliceBackward]
	140639248334032 -> 140639248333936
	140639248334032 [label=SliceBackward]
	140639248357168 -> 140639248334032
	140639248357168 [label=SliceBackward]
	140639248334368 -> 140639248357168
	140639248333792 -> 140639248333648
	140639248333792 [label=SliceBackward]
	140639248334320 -> 140639248333792
	140639248334320 [label=SliceBackward]
	140639248355440 -> 140639248334320
	140639248355440 [label=SliceBackward]
	140639248381936 -> 140639248355440
	140639248381936 [label=SliceBackward]
	140639248334368 -> 140639248381936
	140639248333408 -> 140639248333360
	140639529155392 [label="stages.0.downsample_mlp.norm.weight
 (512)" fillcolor=lightblue]
	140639529155392 -> 140639248333408
	140639248333408 [label=AccumulateGrad]
	140639248333264 -> 140639248333360
	140639529155648 [label="stages.0.downsample_mlp.norm.bias
 (512)" fillcolor=lightblue]
	140639529155648 -> 140639248333264
	140639248333264 [label=AccumulateGrad]
	140639248332832 -> 140639248332976
	140639248332832 [label=TBackward]
	140639248333600 -> 140639248332832
	140639529155456 [label="stages.0.downsample_mlp.reduction.weight
 (128, 512)" fillcolor=lightblue]
	140639529155456 -> 140639248333600
	140639248333600 [label=AccumulateGrad]
	140639248331680 -> 140639248331584
	140639529172736 [label="stages.1.downsample_shortcut.1.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	140639529172736 -> 140639248331680
	140639248331680 [label=AccumulateGrad]
	140639248331536 -> 140639248331440
	140639248331536 [label=ViewBackward]
	140639248331920 -> 140639248331536
	140639248331920 [label=TransposeBackward0]
	140639248332256 -> 140639248331920
	140639248332256 [label=UnsafeViewBackward]
	140639248332064 -> 140639248332256
	140639248332064 [label=MmBackward]
	140639248333840 -> 140639248332064
	140639248333840 [label=ViewBackward]
	140639248355872 -> 140639248333840
	140639248355872 [label=NativeLayerNormBackward]
	140639248333216 -> 140639248355872
	140639248333216 [label=ViewBackward]
	140639248380304 -> 140639248333216
	140639248380304 [label=CatBackward]
	140639248382704 -> 140639248380304
	140639248382704 [label=SliceBackward]
	140639248383232 -> 140639248382704
	140639248383232 [label=SliceBackward]
	140639248383328 -> 140639248383232
	140639248383328 [label=SliceBackward]
	140639248383424 -> 140639248383328
	140639248383424 [label=SliceBackward]
	140639248383520 -> 140639248383424
	140639248383520 [label=ViewBackward]
	140639248383616 -> 140639248383520
	140639248383616 [label=AddBackward0]
	140639248383712 -> 140639248383616
	140639248383712 [label=TransposeBackward0]
	140639248383856 -> 140639248383712
	140639248383856 [label=SqueezeBackward1]
	140639248383952 -> 140639248383856
	140639248383952 [label=ThnnConvDepthwise2DBackward]
	140639248383760 -> 140639248383952
	140639248383760 [label=UnsqueezeBackward0]
	140639248408832 -> 140639248383760
	140639248408832 [label=CopyBackwards]
	140639248408928 -> 140639248408832
	140639248408928 [label=TransposeBackward0]
	140639248409024 -> 140639248408928
	140639248409024 [label=NativeLayerNormBackward]
	140639248409120 -> 140639248409024
	140639248409120 [label=AddBackward0]
	140639248409312 -> 140639248409120
	140639248409312 [label=AddBackward0]
	140639248409456 -> 140639248409312
	140639248409456 [label=TransposeBackward0]
	140639248409600 -> 140639248409456
	140639248409600 [label=SqueezeBackward1]
	140639248409696 -> 140639248409600
	140639248409696 [label=ThnnConvDepthwise2DBackward]
	140639248409792 -> 140639248409696
	140639248409792 [label=UnsqueezeBackward0]
	140639248409936 -> 140639248409792
	140639248409936 [label=CopyBackwards]
	140639248410032 -> 140639248409936
	140639248410032 [label=TransposeBackward0]
	140639248410128 -> 140639248410032
	140639248410128 [label=NativeLayerNormBackward]
	140639248410224 -> 140639248410128
	140639248410224 [label=AddBackward0]
	140639248410416 -> 140639248410224
	140639248410416 [label=TransposeBackward0]
	140639248410560 -> 140639248410416
	140639248410560 [label=ViewBackward]
	140639248331872 -> 140639248410560
	140639248410368 -> 140639248410224
	140639248410368 [label=TransposeBackward0]
	140639248410608 -> 140639248410368
	140639248410608 [label=AddBackward0]
	140639248410704 -> 140639248410608
	140639248410704 [label=UnsafeViewBackward]
	140639248410848 -> 140639248410704
	140639248410848 [label=MmBackward]
	140639248410944 -> 140639248410848
	140639248410944 [label=ViewBackward]
	140639248411088 -> 140639248410944
	140639248411088 [label=ViewBackward]
	140639248411184 -> 140639248411088
	140639248411184 [label=CopyBackwards]
	140639248411280 -> 140639248411184
	140639248411280 [label=TransposeBackward0]
	140639248411376 -> 140639248411280
	140639248411376 [label=ViewBackward]
	140639248411472 -> 140639248411376
	140639248411472 [label=GeluBackward]
	140639248411568 -> 140639248411472
	140639248411568 [label=AddBackward0]
	140639248411664 -> 140639248411568
	140639248411664 [label=UnsafeViewBackward]
	140639248411808 -> 140639248411664
	140639248411808 [label=MmBackward]
	140639248411904 -> 140639248411808
	140639248411904 [label=ViewBackward]
	140639248412048 -> 140639248411904
	140639248412048 [label=CopyBackwards]
	140639248412144 -> 140639248412048
	140639248412144 [label=TransposeBackward0]
	140639248412240 -> 140639248412144
	140639248412240 [label=NativeLayerNormBackward]
	140639248410416 -> 140639248412240
	140639248412336 -> 140639248412240
	140639529161216 [label="stages.1.blocks.0.norm1.weight
 (128)" fillcolor=lightblue]
	140639529161216 -> 140639248412336
	140639248412336 [label=AccumulateGrad]
	140639248412288 -> 140639248412240
	140639529161856 [label="stages.1.blocks.0.norm1.bias
 (128)" fillcolor=lightblue]
	140639529161856 -> 140639248412288
	140639248412288 [label=AccumulateGrad]
	140639248411856 -> 140639248411808
	140639248411856 [label=TBackward]
	140639248412192 -> 140639248411856
	140639529162240 [label="stages.1.blocks.0.token_mlp.fc1.weight
 (128, 784)" fillcolor=lightblue]
	140639529162240 -> 140639248412192
	140639248412192 [label=AccumulateGrad]
	140639248411616 -> 140639248411568
	140639529162624 [label="stages.1.blocks.0.token_mlp.fc1.bias
 (128)" fillcolor=lightblue]
	140639529162624 -> 140639248411616
	140639248411616 [label=AccumulateGrad]
	140639248410896 -> 140639248410848
	140639248410896 [label=TBackward]
	140639248411232 -> 140639248410896
	140639529163008 [label="stages.1.blocks.0.token_mlp.fc2.weight
 (784, 128)" fillcolor=lightblue]
	140639529163008 -> 140639248411232
	140639248411232 [label=AccumulateGrad]
	140639248410464 -> 140639248410608
	140639529163328 [label="stages.1.blocks.0.token_mlp.fc2.bias
 (784)" fillcolor=lightblue]
	140639529163328 -> 140639248410464
	140639248410464 [label=AccumulateGrad]
	140639248410176 -> 140639248410128
	140639529163840 [label="stages.1.blocks.0.norm2.weight
 (128)" fillcolor=lightblue]
	140639529163840 -> 140639248410176
	140639248410176 [label=AccumulateGrad]
	140639248409840 -> 140639248410128
	140639529164288 [label="stages.1.blocks.0.norm2.bias
 (128)" fillcolor=lightblue]
	140639529164288 -> 140639248409840
	140639248409840 [label=AccumulateGrad]
	140639248409744 -> 140639248409696
	140639248409744 [label=UnsqueezeBackward0]
	140639248410080 -> 140639248409744
	140639529160768 [label="stages.1.blocks.0.connect.weight
 (128, 1, 3)" fillcolor=lightblue]
	140639529160768 -> 140639248410080
	140639248410080 [label=AccumulateGrad]
	140639248409408 -> 140639248409312
	140639248409408 [label=AddBackward0]
	140639248409504 -> 140639248409408
	140639248409504 [label=UnsafeViewBackward]
	140639248410272 -> 140639248409504
	140639248410272 [label=MmBackward]
	140639248410656 -> 140639248410272
	140639248410656 [label=ViewBackward]
	140639248410752 -> 140639248410656
	140639248410752 [label=ViewBackward]
	140639248411424 -> 140639248410752
	140639248411424 [label=CopyBackwards]
	140639248411040 -> 140639248411424
	140639248411040 [label=TransposeBackward0]
	140639248410992 -> 140639248411040
	140639248410992 [label=ViewBackward]
	140639248411712 -> 140639248410992
	140639248411712 [label=GeluBackward]
	140639248412384 -> 140639248411712
	140639248412384 [label=AddBackward0]
	140639248412000 -> 140639248412384
	140639248412000 [label=UnsafeViewBackward]
	140639248412528 -> 140639248412000
	140639248412528 [label=MmBackward]
	140639248412624 -> 140639248412528
	140639248412624 [label=ViewBackward]
	140639248429216 -> 140639248412624
	140639248429216 [label=NativeLayerNormBackward]
	140639248409456 -> 140639248429216
	140639248410176 -> 140639248429216
	140639248409840 -> 140639248429216
	140639248412576 -> 140639248412528
	140639248412576 [label=TBackward]
	140639248429264 -> 140639248412576
	140639529161408 [label="stages.1.blocks.0.channel_mlp.fc1.weight
 (256, 128)" fillcolor=lightblue]
	140639529161408 -> 140639248429264
	140639248429264 [label=AccumulateGrad]
	140639248411952 -> 140639248412384
	140639529086592 [label="stages.1.blocks.0.channel_mlp.fc1.bias
 (256)" fillcolor=lightblue]
	140639529086592 -> 140639248411952
	140639248411952 [label=AccumulateGrad]
	140639248409888 -> 140639248410272
	140639248409888 [label=TBackward]
	140639248411328 -> 140639248409888
	140639529004288 [label="stages.1.blocks.0.channel_mlp.fc2.weight
 (128, 256)" fillcolor=lightblue]
	140639529004288 -> 140639248411328
	140639248411328 [label=AccumulateGrad]
	140639248409648 -> 140639248409408
	140639529028096 [label="stages.1.blocks.0.channel_mlp.fc2.bias
 (128)" fillcolor=lightblue]
	140639529028096 -> 140639248409648
	140639248409648 [label=AccumulateGrad]
	140639248409264 -> 140639248409120
	140639248409264 [label=MulBackward0]
	140639248410800 -> 140639248409264
	140639248410800 [label=DivBackward0]
	140639248410320 -> 140639248410800
	140639248410320 [label=TransposeBackward0]
	140639248411520 -> 140639248410320
	140639248411520 [label=AddBackward0]
	140639248411760 -> 140639248411520
	140639248411760 [label=UnsafeViewBackward]
	140639248412480 -> 140639248411760
	140639248412480 [label=MmBackward]
	140639248410512 -> 140639248412480
	140639248410512 [label=ViewBackward]
	140639248429408 -> 140639248410512
	140639248429408 [label=ViewBackward]
	140639248429504 -> 140639248429408
	140639248429504 [label=CopyBackwards]
	140639248429600 -> 140639248429504
	140639248429600 [label=TransposeBackward0]
	140639248429696 -> 140639248429600
	140639248429696 [label=ViewBackward]
	140639248429792 -> 140639248429696
	140639248429792 [label=GeluBackward]
	140639248429888 -> 140639248429792
	140639248429888 [label=AddBackward0]
	140639248429984 -> 140639248429888
	140639248429984 [label=UnsafeViewBackward]
	140639248430128 -> 140639248429984
	140639248430128 [label=MmBackward]
	140639248430224 -> 140639248430128
	140639248430224 [label=ViewBackward]
	140639248430368 -> 140639248430224
	140639248430368 [label=CopyBackwards]
	140639248430464 -> 140639248430368
	140639248430464 [label=TransposeBackward0]
	140639248430560 -> 140639248430464
	140639248430560 [label=NativeLayerNormBackward]
	140639248409312 -> 140639248430560
	140639248430656 -> 140639248430560
	140639529169280 [label="stages.1.blocks.1.norm1.weight
 (128)" fillcolor=lightblue]
	140639529169280 -> 140639248430656
	140639248430656 [label=AccumulateGrad]
	140639248430608 -> 140639248430560
	140639529169536 [label="stages.1.blocks.1.norm1.bias
 (128)" fillcolor=lightblue]
	140639529169536 -> 140639248430608
	140639248430608 [label=AccumulateGrad]
	140639248430176 -> 140639248430128
	140639248430176 [label=TBackward]
	140639248430512 -> 140639248430176
	140639529169856 [label="stages.1.blocks.1.token_mlp.fc1.weight
 (128, 784)" fillcolor=lightblue]
	140639529169856 -> 140639248430512
	140639248430512 [label=AccumulateGrad]
	140639248429936 -> 140639248429888
	140639529169152 [label="stages.1.blocks.1.token_mlp.fc1.bias
 (128)" fillcolor=lightblue]
	140639529169152 -> 140639248429936
	140639248429936 [label=AccumulateGrad]
	140639248429360 -> 140639248412480
	140639248429360 [label=TBackward]
	140639248429552 -> 140639248429360
	140639529170176 [label="stages.1.blocks.1.token_mlp.fc2.weight
 (784, 128)" fillcolor=lightblue]
	140639529170176 -> 140639248429552
	140639248429552 [label=AccumulateGrad]
	140639248411136 -> 140639248411520
	140639529170304 [label="stages.1.blocks.1.token_mlp.fc2.bias
 (784)" fillcolor=lightblue]
	140639529170304 -> 140639248411136
	140639248411136 [label=AccumulateGrad]
	140639248409072 -> 140639248409024
	140639529170496 [label="stages.1.blocks.1.norm2.weight
 (128)" fillcolor=lightblue]
	140639529170496 -> 140639248409072
	140639248409072 [label=AccumulateGrad]
	140639248408736 -> 140639248409024
	140639529170624 [label="stages.1.blocks.1.norm2.bias
 (128)" fillcolor=lightblue]
	140639529170624 -> 140639248408736
	140639248408736 [label=AccumulateGrad]
	140639248408688 -> 140639248383952
	140639248408688 [label=UnsqueezeBackward0]
	140639248408976 -> 140639248408688
	140639529170880 [label="stages.1.blocks.1.connect.weight
 (128, 1, 3)" fillcolor=lightblue]
	140639529170880 -> 140639248408976
	140639248408976 [label=AccumulateGrad]
	140639248383664 -> 140639248383616
	140639248383664 [label=MulBackward0]
	140639248383904 -> 140639248383664
	140639248383904 [label=DivBackward0]
	140639248409216 -> 140639248383904
	140639248409216 [label=AddBackward0]
	140639248408784 -> 140639248409216
	140639248408784 [label=UnsafeViewBackward]
	140639248412096 -> 140639248408784
	140639248412096 [label=MmBackward]
	140639248412432 -> 140639248412096
	140639248412432 [label=ViewBackward]
	140639248429744 -> 140639248412432
	140639248429744 [label=ViewBackward]
	140639248429168 -> 140639248429744
	140639248429168 [label=CopyBackwards]
	140639248429120 -> 140639248429168
	140639248429120 [label=TransposeBackward0]
	140639248430032 -> 140639248429120
	140639248430032 [label=ViewBackward]
	140639248430704 -> 140639248430032
	140639248430704 [label=GeluBackward]
	140639248430320 -> 140639248430704
	140639248430320 [label=AddBackward0]
	140639248430800 -> 140639248430320
	140639248430800 [label=UnsafeViewBackward]
	140639248430944 -> 140639248430800
	140639248430944 [label=MmBackward]
	140639248431040 -> 140639248430944
	140639248431040 [label=ViewBackward]
	140639248431184 -> 140639248431040
	140639248431184 [label=NativeLayerNormBackward]
	140639248383712 -> 140639248431184
	140639248409072 -> 140639248431184
	140639248408736 -> 140639248431184
	140639248430992 -> 140639248430944
	140639248430992 [label=TBackward]
	140639248431232 -> 140639248430992
	140639529171328 [label="stages.1.blocks.1.channel_mlp.fc1.weight
 (256, 128)" fillcolor=lightblue]
	140639529171328 -> 140639248431232
	140639248431232 [label=AccumulateGrad]
	140639248430752 -> 140639248430320
	140639529171456 [label="stages.1.blocks.1.channel_mlp.fc1.bias
 (256)" fillcolor=lightblue]
	140639529171456 -> 140639248430752
	140639248430752 [label=AccumulateGrad]
	140639248409360 -> 140639248412096
	140639248409360 [label=TBackward]
	140639248429840 -> 140639248409360
	140639529171712 [label="stages.1.blocks.1.channel_mlp.fc2.weight
 (128, 256)" fillcolor=lightblue]
	140639529171712 -> 140639248429840
	140639248429840 [label=AccumulateGrad]
	140639248409168 -> 140639248409216
	140639529171840 [label="stages.1.blocks.1.channel_mlp.fc2.bias
 (128)" fillcolor=lightblue]
	140639529171840 -> 140639248409168
	140639248409168 [label=AccumulateGrad]
	140639248383136 -> 140639248380304
	140639248383136 [label=SliceBackward]
	140639248383376 -> 140639248383136
	140639248383376 [label=SliceBackward]
	140639248383568 -> 140639248383376
	140639248383568 [label=SliceBackward]
	140639248383808 -> 140639248383568
	140639248383808 [label=SliceBackward]
	140639248383520 -> 140639248383808
	140639248379968 -> 140639248380304
	140639248379968 [label=SliceBackward]
	140639248382944 -> 140639248379968
	140639248382944 [label=SliceBackward]
	140639248382992 -> 140639248382944
	140639248382992 [label=SliceBackward]
	140639248409552 -> 140639248382992
	140639248409552 [label=SliceBackward]
	140639248383520 -> 140639248409552
	140639248382752 -> 140639248380304
	140639248382752 [label=SliceBackward]
	140639248383280 -> 140639248382752
	140639248383280 [label=SliceBackward]
	140639248408640 -> 140639248383280
	140639248408640 [label=SliceBackward]
	140639248408880 -> 140639248408640
	140639248408880 [label=SliceBackward]
	140639248383520 -> 140639248408880
	140639248381168 -> 140639248355872
	140639529172416 [label="stages.1.downsample_mlp.norm.weight
 (512)" fillcolor=lightblue]
	140639529172416 -> 140639248381168
	140639248381168 [label=AccumulateGrad]
	140639248381504 -> 140639248355872
	140639529172544 [label="stages.1.downsample_mlp.norm.bias
 (512)" fillcolor=lightblue]
	140639529172544 -> 140639248381504
	140639248381504 [label=AccumulateGrad]
	140639248333504 -> 140639248332064
	140639248333504 [label=TBackward]
	140639248355536 -> 140639248333504
	140639529172096 [label="stages.1.downsample_mlp.reduction.weight
 (256, 512)" fillcolor=lightblue]
	140639529172096 -> 140639248355536
	140639248355536 [label=AccumulateGrad]
	140639248331248 -> 140639248331152
	140639512248512 [label="stages.2.downsample_shortcut.1.weight
 (256, 256, 1, 1)" fillcolor=lightblue]
	140639512248512 -> 140639248331248
	140639248331248 [label=AccumulateGrad]
	140639248331104 -> 140639248331008
	140639248331104 [label=ViewBackward]
	140639248331488 -> 140639248331104
	140639248331488 [label=TransposeBackward0]
	140639248331824 -> 140639248331488
	140639248331824 [label=UnsafeViewBackward]
	140639248331632 -> 140639248331824
	140639248331632 [label=MmBackward]
	140639248331200 -> 140639248331632
	140639248331200 [label=ViewBackward]
	140639248409984 -> 140639248331200
	140639248409984 [label=NativeLayerNormBackward]
	140639248383184 -> 140639248409984
	140639248383184 [label=ViewBackward]
	140639248429456 -> 140639248383184
	140639248429456 [label=CatBackward]
	140639248430848 -> 140639248429456
	140639248430848 [label=SliceBackward]
	140639248431376 -> 140639248430848
	140639248431376 [label=SliceBackward]
	140639248431472 -> 140639248431376
	140639248431472 [label=SliceBackward]
	140639248431568 -> 140639248431472
	140639248431568 [label=SliceBackward]
	140639248431664 -> 140639248431568
	140639248431664 [label=ViewBackward]
	140639248431760 -> 140639248431664
	140639248431760 [label=AddBackward0]
	140639248431856 -> 140639248431760
	140639248431856 [label=TransposeBackward0]
	140639248432000 -> 140639248431856
	140639248432000 [label=SqueezeBackward1]
	140639248432096 -> 140639248432000
	140639248432096 [label=ThnnConvDepthwise2DBackward]
	140639248432192 -> 140639248432096
	140639248432192 [label=UnsqueezeBackward0]
	140639248432336 -> 140639248432192
	140639248432336 [label=CopyBackwards]
	140639248432432 -> 140639248432336
	140639248432432 [label=TransposeBackward0]
	140639248432528 -> 140639248432432
	140639248432528 [label=NativeLayerNormBackward]
	140639248432624 -> 140639248432528
	140639248432624 [label=AddBackward0]
	140639248432816 -> 140639248432624
	140639248432816 [label=AddBackward0]
	140639248432960 -> 140639248432816
	140639248432960 [label=TransposeBackward0]
	140639248433104 -> 140639248432960
	140639248433104 [label=SqueezeBackward1]
	140639248433008 -> 140639248433104
	140639248433008 [label=ThnnConvDepthwise2DBackward]
	140639248457936 -> 140639248433008
	140639248457936 [label=UnsqueezeBackward0]
	140639248458080 -> 140639248457936
	140639248458080 [label=CopyBackwards]
	140639248458176 -> 140639248458080
	140639248458176 [label=TransposeBackward0]
	140639248458272 -> 140639248458176
	140639248458272 [label=NativeLayerNormBackward]
	140639248458368 -> 140639248458272
	140639248458368 [label=AddBackward0]
	140639248458560 -> 140639248458368
	140639248458560 [label=AddBackward0]
	140639248458704 -> 140639248458560
	140639248458704 [label=TransposeBackward0]
	140639248458848 -> 140639248458704
	140639248458848 [label=SqueezeBackward1]
	140639248458944 -> 140639248458848
	140639248458944 [label=ThnnConvDepthwise2DBackward]
	140639248459040 -> 140639248458944
	140639248459040 [label=UnsqueezeBackward0]
	140639248459184 -> 140639248459040
	140639248459184 [label=CopyBackwards]
	140639248459280 -> 140639248459184
	140639248459280 [label=TransposeBackward0]
	140639248459376 -> 140639248459280
	140639248459376 [label=NativeLayerNormBackward]
	140639248459472 -> 140639248459376
	140639248459472 [label=AddBackward0]
	140639248459664 -> 140639248459472
	140639248459664 [label=AddBackward0]
	140639248459808 -> 140639248459664
	140639248459808 [label=TransposeBackward0]
	140639248459952 -> 140639248459808
	140639248459952 [label=SqueezeBackward1]
	140639248460048 -> 140639248459952
	140639248460048 [label=ThnnConvDepthwise2DBackward]
	140639248460144 -> 140639248460048
	140639248460144 [label=UnsqueezeBackward0]
	140639248460288 -> 140639248460144
	140639248460288 [label=CopyBackwards]
	140639248460384 -> 140639248460288
	140639248460384 [label=TransposeBackward0]
	140639248460480 -> 140639248460384
	140639248460480 [label=NativeLayerNormBackward]
	140639248460576 -> 140639248460480
	140639248460576 [label=AddBackward0]
	140639248460768 -> 140639248460576
	140639248460768 [label=TransposeBackward0]
	140639248460912 -> 140639248460768
	140639248460912 [label=ViewBackward]
	140639248331440 -> 140639248460912
	140639248460720 -> 140639248460576
	140639248460720 [label=TransposeBackward0]
	140639248460960 -> 140639248460720
	140639248460960 [label=AddBackward0]
	140639248461056 -> 140639248460960
	140639248461056 [label=UnsafeViewBackward]
	140639248461200 -> 140639248461056
	140639248461200 [label=MmBackward]
	140639248461296 -> 140639248461200
	140639248461296 [label=ViewBackward]
	140639248461440 -> 140639248461296
	140639248461440 [label=ViewBackward]
	140639248461536 -> 140639248461440
	140639248461536 [label=CopyBackwards]
	140639248461632 -> 140639248461536
	140639248461632 [label=TransposeBackward0]
	140639248461728 -> 140639248461632
	140639248461728 [label=ViewBackward]
	140639248461776 -> 140639248461728
	140639248461776 [label=GeluBackward]
	140639248478416 -> 140639248461776
	140639248478416 [label=AddBackward0]
	140639248478560 -> 140639248478416
	140639248478560 [label=UnsafeViewBackward]
	140639248478704 -> 140639248478560
	140639248478704 [label=MmBackward]
	140639248478848 -> 140639248478704
	140639248478848 [label=ViewBackward]
	140639248478992 -> 140639248478848
	140639248478992 [label=CopyBackwards]
	140639248479136 -> 140639248478992
	140639248479136 [label=TransposeBackward0]
	140639248479232 -> 140639248479136
	140639248479232 [label=NativeLayerNormBackward]
	140639248460768 -> 140639248479232
	140639248479376 -> 140639248479232
	140639522021952 [label="stages.2.blocks.0.norm1.weight
 (256)" fillcolor=lightblue]
	140639522021952 -> 140639248479376
	140639248479376 [label=AccumulateGrad]
	140639248479328 -> 140639248479232
	140639522022080 [label="stages.2.blocks.0.norm1.bias
 (256)" fillcolor=lightblue]
	140639522022080 -> 140639248479328
	140639248479328 [label=AccumulateGrad]
	140639248478800 -> 140639248478704
	140639248478800 [label=TBackward]
	140639248479184 -> 140639248478800
	140639522022400 [label="stages.2.blocks.0.token_mlp.fc1.weight
 (256, 196)" fillcolor=lightblue]
	140639522022400 -> 140639248479184
	140639248479184 [label=AccumulateGrad]
	140639248478512 -> 140639248478416
	140639522022528 [label="stages.2.blocks.0.token_mlp.fc1.bias
 (256)" fillcolor=lightblue]
	140639522022528 -> 140639248478512
	140639248478512 [label=AccumulateGrad]
	140639248461248 -> 140639248461200
	140639248461248 [label=TBackward]
	140639248461584 -> 140639248461248
	140639522022784 [label="stages.2.blocks.0.token_mlp.fc2.weight
 (196, 256)" fillcolor=lightblue]
	140639522022784 -> 140639248461584
	140639248461584 [label=AccumulateGrad]
	140639248460816 -> 140639248460960
	140639522022912 [label="stages.2.blocks.0.token_mlp.fc2.bias
 (196)" fillcolor=lightblue]
	140639522022912 -> 140639248460816
	140639248460816 [label=AccumulateGrad]
	140639248460528 -> 140639248460480
	140639522023104 [label="stages.2.blocks.0.norm2.weight
 (256)" fillcolor=lightblue]
	140639522023104 -> 140639248460528
	140639248460528 [label=AccumulateGrad]
	140639248460192 -> 140639248460480
	140639522023232 [label="stages.2.blocks.0.norm2.bias
 (256)" fillcolor=lightblue]
	140639522023232 -> 140639248460192
	140639248460192 [label=AccumulateGrad]
	140639248460096 -> 140639248460048
	140639248460096 [label=UnsqueezeBackward0]
	140639248460432 -> 140639248460096
	140639522023488 [label="stages.2.blocks.0.connect.weight
 (256, 1, 3)" fillcolor=lightblue]
	140639522023488 -> 140639248460432
	140639248460432 [label=AccumulateGrad]
	140639248459760 -> 140639248459664
	140639248459760 [label=AddBackward0]
	140639248459856 -> 140639248459760
	140639248459856 [label=UnsafeViewBackward]
	140639248460624 -> 140639248459856
	140639248460624 [label=MmBackward]
	140639248461008 -> 140639248460624
	140639248461008 [label=ViewBackward]
	140639248461104 -> 140639248461008
	140639248461104 [label=ViewBackward]
	140639248461344 -> 140639248461104
	140639248461344 [label=CopyBackwards]
	140639248461392 -> 140639248461344
	140639248461392 [label=TransposeBackward0]
	140639248460864 -> 140639248461392
	140639248460864 [label=ViewBackward]
	140639248479088 -> 140639248460864
	140639248479088 [label=GeluBackward]
	140639248479280 -> 140639248479088
	140639248479280 [label=AddBackward0]
	140639248479520 -> 140639248479280
	140639248479520 [label=UnsafeViewBackward]
	140639248479664 -> 140639248479520
	140639248479664 [label=MmBackward]
	140639248479760 -> 140639248479664
	140639248479760 [label=ViewBackward]
	140639248479904 -> 140639248479760
	140639248479904 [label=NativeLayerNormBackward]
	140639248459808 -> 140639248479904
	140639248460528 -> 140639248479904
	140639248460192 -> 140639248479904
	140639248479712 -> 140639248479664
	140639248479712 [label=TBackward]
	140639248479952 -> 140639248479712
	140639522023936 [label="stages.2.blocks.0.channel_mlp.fc1.weight
 (1024, 256)" fillcolor=lightblue]
	140639522023936 -> 140639248479952
	140639248479952 [label=AccumulateGrad]
	140639248478944 -> 140639248479280
	140639522024064 [label="stages.2.blocks.0.channel_mlp.fc1.bias
 (1024)" fillcolor=lightblue]
	140639522024064 -> 140639248478944
	140639248478944 [label=AccumulateGrad]
	140639248460240 -> 140639248460624
	140639248460240 [label=TBackward]
	140639248461680 -> 140639248460240
	140639522024320 [label="stages.2.blocks.0.channel_mlp.fc2.weight
 (256, 1024)" fillcolor=lightblue]
	140639522024320 -> 140639248461680
	140639248461680 [label=AccumulateGrad]
	140639248460000 -> 140639248459760
	140639522024448 [label="stages.2.blocks.0.channel_mlp.fc2.bias
 (256)" fillcolor=lightblue]
	140639522024448 -> 140639248460000
	140639248460000 [label=AccumulateGrad]
	140639248459616 -> 140639248459472
	140639248459616 [label=MulBackward0]
	140639248461152 -> 140639248459616
	140639248461152 [label=DivBackward0]
	140639248460672 -> 140639248461152
	140639248460672 [label=TransposeBackward0]
	140639248461488 -> 140639248460672
	140639248461488 [label=AddBackward0]
	140639248478752 -> 140639248461488
	140639248478752 [label=UnsafeViewBackward]
	140639248479568 -> 140639248478752
	140639248479568 [label=MmBackward]
	140639248480048 -> 140639248479568
	140639248480048 [label=ViewBackward]
	140639248480096 -> 140639248480048
	140639248480096 [label=ViewBackward]
	140639248480192 -> 140639248480096
	140639248480192 [label=CopyBackwards]
	140639248480288 -> 140639248480192
	140639248480288 [label=TransposeBackward0]
	140639248480384 -> 140639248480288
	140639248480384 [label=ViewBackward]
	140639248480480 -> 140639248480384
	140639248480480 [label=GeluBackward]
	140639248480576 -> 140639248480480
	140639248480576 [label=AddBackward0]
	140639248480672 -> 140639248480576
	140639248480672 [label=UnsafeViewBackward]
	140639248480816 -> 140639248480672
	140639248480816 [label=MmBackward]
	140639248480912 -> 140639248480816
	140639248480912 [label=ViewBackward]
	140639248481056 -> 140639248480912
	140639248481056 [label=CopyBackwards]
	140639248481152 -> 140639248481056
	140639248481152 [label=TransposeBackward0]
	140639248481248 -> 140639248481152
	140639248481248 [label=NativeLayerNormBackward]
	140639248459664 -> 140639248481248
	140639248481344 -> 140639248481248
	140639522024768 [label="stages.2.blocks.1.norm1.weight
 (256)" fillcolor=lightblue]
	140639522024768 -> 140639248481344
	140639248481344 [label=AccumulateGrad]
	140639248481296 -> 140639248481248
	140639522024896 [label="stages.2.blocks.1.norm1.bias
 (256)" fillcolor=lightblue]
	140639522024896 -> 140639248481296
	140639248481296 [label=AccumulateGrad]
	140639248480864 -> 140639248480816
	140639248480864 [label=TBackward]
	140639248481200 -> 140639248480864
	140639522025216 [label="stages.2.blocks.1.token_mlp.fc1.weight
 (256, 196)" fillcolor=lightblue]
	140639522025216 -> 140639248481200
	140639248481200 [label=AccumulateGrad]
	140639248480624 -> 140639248480576
	140639522025344 [label="stages.2.blocks.1.token_mlp.fc1.bias
 (256)" fillcolor=lightblue]
	140639522025344 -> 140639248480624
	140639248480624 [label=AccumulateGrad]
	140639248479616 -> 140639248479568
	140639248479616 [label=TBackward]
	140639248480240 -> 140639248479616
	140639522099392 [label="stages.2.blocks.1.token_mlp.fc2.weight
 (196, 256)" fillcolor=lightblue]
	140639522099392 -> 140639248480240
	140639248480240 [label=AccumulateGrad]
	140639248478464 -> 140639248461488
	140639522099520 [label="stages.2.blocks.1.token_mlp.fc2.bias
 (196)" fillcolor=lightblue]
	140639522099520 -> 140639248478464
	140639248478464 [label=AccumulateGrad]
	140639248459424 -> 140639248459376
	140639522099712 [label="stages.2.blocks.1.norm2.weight
 (256)" fillcolor=lightblue]
	140639522099712 -> 140639248459424
	140639248459424 [label=AccumulateGrad]
	140639248459088 -> 140639248459376
	140639522099840 [label="stages.2.blocks.1.norm2.bias
 (256)" fillcolor=lightblue]
	140639522099840 -> 140639248459088
	140639248459088 [label=AccumulateGrad]
	140639248458992 -> 140639248458944
	140639248458992 [label=UnsqueezeBackward0]
	140639248459328 -> 140639248458992
	140639522100096 [label="stages.2.blocks.1.connect.weight
 (256, 1, 3)" fillcolor=lightblue]
	140639522100096 -> 140639248459328
	140639248459328 [label=AccumulateGrad]
	140639248458656 -> 140639248458560
	140639248458656 [label=MulBackward0]
	140639248458752 -> 140639248458656
	140639248458752 [label=DivBackward0]
	140639248459568 -> 140639248458752
	140639248459568 [label=AddBackward0]
	140639248459136 -> 140639248459568
	140639248459136 [label=UnsafeViewBackward]
	140639248459712 -> 140639248459136
	140639248459712 [label=MmBackward]
	140639248459904 -> 140639248459712
	140639248459904 [label=ViewBackward]
	140639248480432 -> 140639248459904
	140639248480432 [label=ViewBackward]
	140639248479856 -> 140639248480432
	140639248479856 [label=CopyBackwards]
	140639248479808 -> 140639248479856
	140639248479808 [label=TransposeBackward0]
	140639248480720 -> 140639248479808
	140639248480720 [label=ViewBackward]
	140639248481392 -> 140639248480720
	140639248481392 [label=GeluBackward]
	140639248481008 -> 140639248481392
	140639248481008 [label=AddBackward0]
	140639248481488 -> 140639248481008
	140639248481488 [label=UnsafeViewBackward]
	140639248481632 -> 140639248481488
	140639248481632 [label=MmBackward]
	140639248481728 -> 140639248481632
	140639248481728 [label=ViewBackward]
	140639248481872 -> 140639248481728
	140639248481872 [label=NativeLayerNormBackward]
	140639248458704 -> 140639248481872
	140639248459424 -> 140639248481872
	140639248459088 -> 140639248481872
	140639248481680 -> 140639248481632
	140639248481680 [label=TBackward]
	140639248481920 -> 140639248481680
	140639522100544 [label="stages.2.blocks.1.channel_mlp.fc1.weight
 (1024, 256)" fillcolor=lightblue]
	140639522100544 -> 140639248481920
	140639248481920 [label=AccumulateGrad]
	140639248481440 -> 140639248481008
	140639522100672 [label="stages.2.blocks.1.channel_mlp.fc1.bias
 (1024)" fillcolor=lightblue]
	140639522100672 -> 140639248481440
	140639248481440 [label=AccumulateGrad]
	140639248480144 -> 140639248459712
	140639248480144 [label=TBackward]
	140639248480528 -> 140639248480144
	140639522100928 [label="stages.2.blocks.1.channel_mlp.fc2.weight
 (256, 1024)" fillcolor=lightblue]
	140639522100928 -> 140639248480528
	140639248480528 [label=AccumulateGrad]
	140639248459520 -> 140639248459568
	140639522101056 [label="stages.2.blocks.1.channel_mlp.fc2.bias
 (256)" fillcolor=lightblue]
	140639522101056 -> 140639248459520
	140639248459520 [label=AccumulateGrad]
	140639248458512 -> 140639248458368
	140639248458512 [label=MulBackward0]
	140639248459232 -> 140639248458512
	140639248459232 [label=DivBackward0]
	140639248460336 -> 140639248459232
	140639248460336 [label=TransposeBackward0]
	140639248458608 -> 140639248460336
	140639248458608 [label=AddBackward0]
	140639248481104 -> 140639248458608
	140639248481104 [label=UnsafeViewBackward]
	140639248478368 -> 140639248481104
	140639248478368 [label=MmBackward]
	140639248481536 -> 140639248478368
	140639248481536 [label=ViewBackward]
	140639248481776 -> 140639248481536
	140639248481776 [label=ViewBackward]
	140639248482064 -> 140639248481776
	140639248482064 [label=CopyBackwards]
	140639248482160 -> 140639248482064
	140639248482160 [label=TransposeBackward0]
	140639248482256 -> 140639248482160
	140639248482256 [label=ViewBackward]
	140639248481584 -> 140639248482256
	140639248481584 [label=GeluBackward]
	140639248507088 -> 140639248481584
	140639248507088 [label=AddBackward0]
	140639248507184 -> 140639248507088
	140639248507184 [label=UnsafeViewBackward]
	140639248507328 -> 140639248507184
	140639248507328 [label=MmBackward]
	140639248507424 -> 140639248507328
	140639248507424 [label=ViewBackward]
	140639248507568 -> 140639248507424
	140639248507568 [label=CopyBackwards]
	140639248507664 -> 140639248507568
	140639248507664 [label=TransposeBackward0]
	140639248507760 -> 140639248507664
	140639248507760 [label=NativeLayerNormBackward]
	140639248458560 -> 140639248507760
	140639248507856 -> 140639248507760
	140639522101312 [label="stages.2.blocks.2.norm1.weight
 (256)" fillcolor=lightblue]
	140639522101312 -> 140639248507856
	140639248507856 [label=AccumulateGrad]
	140639248507808 -> 140639248507760
	140639522101440 [label="stages.2.blocks.2.norm1.bias
 (256)" fillcolor=lightblue]
	140639522101440 -> 140639248507808
	140639248507808 [label=AccumulateGrad]
	140639248507376 -> 140639248507328
	140639248507376 [label=TBackward]
	140639248507712 -> 140639248507376
	140639522101760 [label="stages.2.blocks.2.token_mlp.fc1.weight
 (256, 196)" fillcolor=lightblue]
	140639522101760 -> 140639248507712
	140639248507712 [label=AccumulateGrad]
	140639248507136 -> 140639248507088
	140639522101888 [label="stages.2.blocks.2.token_mlp.fc1.bias
 (256)" fillcolor=lightblue]
	140639522101888 -> 140639248507136
	140639248507136 [label=AccumulateGrad]
	140639248481968 -> 140639248478368
	140639248481968 [label=TBackward]
	140639248482112 -> 140639248481968
	140639522102144 [label="stages.2.blocks.2.token_mlp.fc2.weight
 (196, 256)" fillcolor=lightblue]
	140639522102144 -> 140639248482112
	140639248482112 [label=AccumulateGrad]
	140639248480768 -> 140639248458608
	140639522102272 [label="stages.2.blocks.2.token_mlp.fc2.bias
 (196)" fillcolor=lightblue]
	140639522102272 -> 140639248480768
	140639248480768 [label=AccumulateGrad]
	140639248458320 -> 140639248458272
	140639522102464 [label="stages.2.blocks.2.norm2.weight
 (256)" fillcolor=lightblue]
	140639522102464 -> 140639248458320
	140639248458320 [label=AccumulateGrad]
	140639248457984 -> 140639248458272
	140639522102592 [label="stages.2.blocks.2.norm2.bias
 (256)" fillcolor=lightblue]
	140639522102592 -> 140639248457984
	140639248457984 [label=AccumulateGrad]
	140639248457888 -> 140639248433008
	140639248457888 [label=UnsqueezeBackward0]
	140639248458224 -> 140639248457888
	140639522102848 [label="stages.2.blocks.2.connect.weight
 (256, 1, 3)" fillcolor=lightblue]
	140639522102848 -> 140639248458224
	140639248458224 [label=AccumulateGrad]
	140639248432912 -> 140639248432816
	140639248432912 [label=MulBackward0]
	140639248433056 -> 140639248432912
	140639248433056 [label=DivBackward0]
	140639248458464 -> 140639248433056
	140639248458464 [label=AddBackward0]
	140639248458032 -> 140639248458464
	140639248458032 [label=UnsafeViewBackward]
	140639248458800 -> 140639248458032
	140639248458800 [label=MmBackward]
	140639248481824 -> 140639248458800
	140639248481824 [label=ViewBackward]
	140639248482208 -> 140639248481824
	140639248482208 [label=ViewBackward]
	140639248482016 -> 140639248482208
	140639248482016 [label=CopyBackwards]
	140639248506944 -> 140639248482016
	140639248506944 [label=TransposeBackward0]
	140639248507232 -> 140639248506944
	140639248507232 [label=ViewBackward]
	140639248507904 -> 140639248507232
	140639248507904 [label=GeluBackward]
	140639248507520 -> 140639248507904
	140639248507520 [label=AddBackward0]
	140639248508000 -> 140639248507520
	140639248508000 [label=UnsafeViewBackward]
	140639248508144 -> 140639248508000
	140639248508144 [label=MmBackward]
	140639248508240 -> 140639248508144
	140639248508240 [label=ViewBackward]
	140639248508384 -> 140639248508240
	140639248508384 [label=NativeLayerNormBackward]
	140639248432960 -> 140639248508384
	140639248458320 -> 140639248508384
	140639248457984 -> 140639248508384
	140639248508192 -> 140639248508144
	140639248508192 [label=TBackward]
	140639248508432 -> 140639248508192
	140639522172992 [label="stages.2.blocks.2.channel_mlp.fc1.weight
 (1024, 256)" fillcolor=lightblue]
	140639522172992 -> 140639248508432
	140639248508432 [label=AccumulateGrad]
	140639248507952 -> 140639248507520
	140639522173120 [label="stages.2.blocks.2.channel_mlp.fc1.bias
 (1024)" fillcolor=lightblue]
	140639522173120 -> 140639248507952
	140639248507952 [label=AccumulateGrad]
	140639248480336 -> 140639248458800
	140639248480336 [label=TBackward]
	140639248480000 -> 140639248480336
	140639522173376 [label="stages.2.blocks.2.channel_mlp.fc2.weight
 (256, 1024)" fillcolor=lightblue]
	140639522173376 -> 140639248480000
	140639248480000 [label=AccumulateGrad]
	140639248458416 -> 140639248458464
	140639522173504 [label="stages.2.blocks.2.channel_mlp.fc2.bias
 (256)" fillcolor=lightblue]
	140639522173504 -> 140639248458416
	140639248458416 [label=AccumulateGrad]
	140639248432768 -> 140639248432624
	140639248432768 [label=MulBackward0]
	140639248479472 -> 140639248432768
	140639248479472 [label=DivBackward0]
	140639248432864 -> 140639248479472
	140639248432864 [label=TransposeBackward0]
	140639248458896 -> 140639248432864
	140639248458896 [label=AddBackward0]
	140639248457792 -> 140639248458896
	140639248457792 [label=UnsafeViewBackward]
	140639248506992 -> 140639248457792
	140639248506992 [label=MmBackward]
	140639248508048 -> 140639248506992
	140639248508048 [label=ViewBackward]
	140639248508288 -> 140639248508048
	140639248508288 [label=ViewBackward]
	140639248508576 -> 140639248508288
	140639248508576 [label=CopyBackwards]
	140639248508672 -> 140639248508576
	140639248508672 [label=TransposeBackward0]
	140639248508768 -> 140639248508672
	140639248508768 [label=ViewBackward]
	140639248508864 -> 140639248508768
	140639248508864 [label=GeluBackward]
	140639248508960 -> 140639248508864
	140639248508960 [label=AddBackward0]
	140639248509056 -> 140639248508960
	140639248509056 [label=UnsafeViewBackward]
	140639248509200 -> 140639248509056
	140639248509200 [label=MmBackward]
	140639248509296 -> 140639248509200
	140639248509296 [label=ViewBackward]
	140639248509440 -> 140639248509296
	140639248509440 [label=CopyBackwards]
	140639248509536 -> 140639248509440
	140639248509536 [label=TransposeBackward0]
	140639248509632 -> 140639248509536
	140639248509632 [label=NativeLayerNormBackward]
	140639248432816 -> 140639248509632
	140639248509728 -> 140639248509632
	140639522173760 [label="stages.2.blocks.3.norm1.weight
 (256)" fillcolor=lightblue]
	140639522173760 -> 140639248509728
	140639248509728 [label=AccumulateGrad]
	140639248509680 -> 140639248509632
	140639522173888 [label="stages.2.blocks.3.norm1.bias
 (256)" fillcolor=lightblue]
	140639522173888 -> 140639248509680
	140639248509680 [label=AccumulateGrad]
	140639248509248 -> 140639248509200
	140639248509248 [label=TBackward]
	140639248509584 -> 140639248509248
	140639522174208 [label="stages.2.blocks.3.token_mlp.fc1.weight
 (256, 196)" fillcolor=lightblue]
	140639522174208 -> 140639248509584
	140639248509584 [label=AccumulateGrad]
	140639248509008 -> 140639248508960
	140639522174336 [label="stages.2.blocks.3.token_mlp.fc1.bias
 (256)" fillcolor=lightblue]
	140639522174336 -> 140639248509008
	140639248509008 [label=AccumulateGrad]
	140639248508480 -> 140639248506992
	140639248508480 [label=TBackward]
	140639248508624 -> 140639248508480
	140639522174592 [label="stages.2.blocks.3.token_mlp.fc2.weight
 (196, 256)" fillcolor=lightblue]
	140639522174592 -> 140639248508624
	140639248508624 [label=AccumulateGrad]
	140639248507616 -> 140639248458896
	140639522174720 [label="stages.2.blocks.3.token_mlp.fc2.bias
 (196)" fillcolor=lightblue]
	140639522174720 -> 140639248507616
	140639248507616 [label=AccumulateGrad]
	140639248432576 -> 140639248432528
	140639522174912 [label="stages.2.blocks.3.norm2.weight
 (256)" fillcolor=lightblue]
	140639522174912 -> 140639248432576
	140639248432576 [label=AccumulateGrad]
	140639248432240 -> 140639248432528
	140639522175040 [label="stages.2.blocks.3.norm2.bias
 (256)" fillcolor=lightblue]
	140639522175040 -> 140639248432240
	140639248432240 [label=AccumulateGrad]
	140639248432144 -> 140639248432096
	140639248432144 [label=UnsqueezeBackward0]
	140639248432480 -> 140639248432144
	140639522175296 [label="stages.2.blocks.3.connect.weight
 (256, 1, 3)" fillcolor=lightblue]
	140639522175296 -> 140639248432480
	140639248432480 [label=AccumulateGrad]
	140639248431808 -> 140639248431760
	140639248431808 [label=MulBackward0]
	140639248431904 -> 140639248431808
	140639248431904 [label=DivBackward0]
	140639248432720 -> 140639248431904
	140639248432720 [label=AddBackward0]
	140639248432288 -> 140639248432720
	140639248432288 [label=UnsafeViewBackward]
	140639248457840 -> 140639248432288
	140639248457840 [label=MmBackward]
	140639248480960 -> 140639248457840
	140639248480960 [label=ViewBackward]
	140639248508816 -> 140639248480960
	140639248508816 [label=ViewBackward]
	140639248508528 -> 140639248508816
	140639248508528 [label=CopyBackwards]
	140639248508096 -> 140639248508528
	140639248508096 [label=TransposeBackward0]
	140639248509104 -> 140639248508096
	140639248509104 [label=ViewBackward]
	140639248509776 -> 140639248509104
	140639248509776 [label=GeluBackward]
	140639248509392 -> 140639248509776
	140639248509392 [label=AddBackward0]
	140639248509872 -> 140639248509392
	140639248509872 [label=UnsafeViewBackward]
	140639248510016 -> 140639248509872
	140639248510016 [label=MmBackward]
	140639248510112 -> 140639248510016
	140639248510112 [label=ViewBackward]
	140639248510256 -> 140639248510112
	140639248510256 [label=NativeLayerNormBackward]
	140639248431856 -> 140639248510256
	140639248432576 -> 140639248510256
	140639248432240 -> 140639248510256
	140639248510064 -> 140639248510016
	140639248510064 [label=TBackward]
	140639248510304 -> 140639248510064
	140639522175744 [label="stages.2.blocks.3.channel_mlp.fc1.weight
 (1024, 256)" fillcolor=lightblue]
	140639522175744 -> 140639248510304
	140639248510304 [label=AccumulateGrad]
	140639248509824 -> 140639248509392
	140639522175872 [label="stages.2.blocks.3.channel_mlp.fc1.bias
 (1024)" fillcolor=lightblue]
	140639522175872 -> 140639248509824
	140639248509824 [label=AccumulateGrad]
	140639248508336 -> 140639248457840
	140639248508336 [label=TBackward]
	140639248508912 -> 140639248508336
	140639522176128 [label="stages.2.blocks.3.channel_mlp.fc2.weight
 (256, 1024)" fillcolor=lightblue]
	140639522176128 -> 140639248508912
	140639248508912 [label=AccumulateGrad]
	140639248432672 -> 140639248432720
	140639522176256 [label="stages.2.blocks.3.channel_mlp.fc2.bias
 (256)" fillcolor=lightblue]
	140639522176256 -> 140639248432672
	140639248432672 [label=AccumulateGrad]
	140639248431280 -> 140639248429456
	140639248431280 [label=SliceBackward]
	140639248431520 -> 140639248431280
	140639248431520 [label=SliceBackward]
	140639248431712 -> 140639248431520
	140639248431712 [label=SliceBackward]
	140639248432048 -> 140639248431712
	140639248432048 [label=SliceBackward]
	140639248431664 -> 140639248432048
	140639248429648 -> 140639248429456
	140639248429648 [label=SliceBackward]
	140639248431088 -> 140639248429648
	140639248431088 [label=SliceBackward]
	140639248432384 -> 140639248431088
	140639248432384 [label=SliceBackward]
	140639248458128 -> 140639248432384
	140639248458128 [label=SliceBackward]
	140639248431664 -> 140639248458128
	140639248430896 -> 140639248429456
	140639248430896 [label=SliceBackward]
	140639248431136 -> 140639248430896
	140639248431136 [label=SliceBackward]
	140639248431424 -> 140639248431136
	140639248431424 [label=SliceBackward]
	140639248509152 -> 140639248431424
	140639248509152 [label=SliceBackward]
	140639248431664 -> 140639248509152
	140639248429312 -> 140639248409984
	140639522176832 [label="stages.2.downsample_mlp.norm.weight
 (1024)" fillcolor=lightblue]
	140639522176832 -> 140639248429312
	140639248429312 [label=AccumulateGrad]
	140639248430080 -> 140639248409984
	140639522176960 [label="stages.2.downsample_mlp.norm.bias
 (1024)" fillcolor=lightblue]
	140639522176960 -> 140639248430080
	140639248430080 [label=AccumulateGrad]
	140639248383472 -> 140639248331632
	140639248383472 [label=TBackward]
	140639248382272 -> 140639248383472
	140639522176512 [label="stages.2.downsample_mlp.reduction.weight
 (256, 1024)" fillcolor=lightblue]
	140639522176512 -> 140639248382272
	140639248382272 [label=AccumulateGrad]
	140639375794032 -> 140639375793888
	140639375794032 [label=TransposeBackward0]
	140639248331056 -> 140639375794032
	140639248331056 [label=AddBackward0]
	140639248331392 -> 140639248331056
	140639248331392 [label=UnsafeViewBackward]
	140639248382128 -> 140639248331392
	140639248382128 [label=MmBackward]
	140639248431328 -> 140639248382128
	140639248431328 [label=ViewBackward]
	140639248431616 -> 140639248431328
	140639248431616 [label=GeluBackward]
	140639248509488 -> 140639248431616
	140639248509488 [label=AddBackward0]
	140639248509344 -> 140639248509488
	140639248509344 [label=UnsafeViewBackward]
	140639248509920 -> 140639248509344
	140639248509920 [label=MmBackward]
	140639248510400 -> 140639248509920
	140639248510400 [label=ViewBackward]
	140639248510448 -> 140639248510400
	140639248510448 [label=CopyBackwards]
	140639248510544 -> 140639248510448
	140639248510544 [label=TransposeBackward0]
	140639248510640 -> 140639248510544
	140639248510640 [label=NativeLayerNormBackward]
	140639375794080 -> 140639248510640
	140639248510736 -> 140639248510640
	140639512249280 [label="stages.3.blocks.0.norm1.weight
 (256)" fillcolor=lightblue]
	140639512249280 -> 140639248510736
	140639248510736 [label=AccumulateGrad]
	140639248510688 -> 140639248510640
	140639512249408 [label="stages.3.blocks.0.norm1.bias
 (256)" fillcolor=lightblue]
	140639512249408 -> 140639248510688
	140639248510688 [label=AccumulateGrad]
	140639248509968 -> 140639248509920
	140639248509968 [label=TBackward]
	140639248510592 -> 140639248509968
	140639512249728 [label="stages.3.blocks.0.token_mlp.fc1.weight
 (256, 49)" fillcolor=lightblue]
	140639512249728 -> 140639248510592
	140639248510592 [label=AccumulateGrad]
	140639248507280 -> 140639248509488
	140639512249856 [label="stages.3.blocks.0.token_mlp.fc1.bias
 (256)" fillcolor=lightblue]
	140639512249856 -> 140639248507280
	140639248507280 [label=AccumulateGrad]
	140639248431952 -> 140639248382128
	140639248431952 [label=TBackward]
	140639248430416 -> 140639248431952
	140639512250112 [label="stages.3.blocks.0.token_mlp.fc2.weight
 (49, 256)" fillcolor=lightblue]
	140639512250112 -> 140639248430416
	140639248430416 [label=AccumulateGrad]
	140639248332544 -> 140639248331056
	140639512250240 [label="stages.3.blocks.0.token_mlp.fc2.bias
 (49)" fillcolor=lightblue]
	140639512250240 -> 140639248332544
	140639248332544 [label=AccumulateGrad]
	140639375793840 -> 140639375793744
	140639512250432 [label="stages.3.blocks.0.norm2.weight
 (256)" fillcolor=lightblue]
	140639512250432 -> 140639375793840
	140639375793840 [label=AccumulateGrad]
	140639375793792 -> 140639375793744
	140639512250560 [label="stages.3.blocks.0.norm2.bias
 (256)" fillcolor=lightblue]
	140639512250560 -> 140639375793792
	140639375793792 [label=AccumulateGrad]
	140639375793312 -> 140639375793216
	140639375793312 [label=UnsqueezeBackward0]
	140639375793696 -> 140639375793312
	140639512250816 [label="stages.3.blocks.0.connect.weight
 (256, 1, 3)" fillcolor=lightblue]
	140639512250816 -> 140639375793696
	140639375793696 [label=AccumulateGrad]
	140639375792928 -> 140639375792832
	140639375792928 [label=AddBackward0]
	140639375793264 -> 140639375792928
	140639375793264 [label=UnsafeViewBackward]
	140639375793936 -> 140639375793264
	140639375793936 [label=MmBackward]
	140639248430272 -> 140639375793936
	140639248430272 [label=ViewBackward]
	140639248333120 -> 140639248430272
	140639248333120 [label=GeluBackward]
	140639248330960 -> 140639248333120
	140639248330960 [label=AddBackward0]
	140639248507472 -> 140639248330960
	140639248507472 [label=UnsafeViewBackward]
	140639248510160 -> 140639248507472
	140639248510160 [label=MmBackward]
	140639248510832 -> 140639248510160
	140639248510832 [label=ViewBackward]
	140639248510928 -> 140639248510832
	140639248510928 [label=NativeLayerNormBackward]
	140639375792976 -> 140639248510928
	140639375793840 -> 140639248510928
	140639375793792 -> 140639248510928
	140639248510208 -> 140639248510160
	140639248510208 [label=TBackward]
	140639248510880 -> 140639248510208
	140639512251264 [label="stages.3.blocks.0.channel_mlp.fc1.weight
 (1024, 256)" fillcolor=lightblue]
	140639512251264 -> 140639248510880
	140639248510880 [label=AccumulateGrad]
	140639248510496 -> 140639248330960
	140639512251392 [label="stages.3.blocks.0.channel_mlp.fc1.bias
 (1024)" fillcolor=lightblue]
	140639512251392 -> 140639248510496
	140639248510496 [label=AccumulateGrad]
	140639375793456 -> 140639375793936
	140639375793456 [label=TBackward]
	140639248330816 -> 140639375793456
	140639512251648 [label="stages.3.blocks.0.channel_mlp.fc2.weight
 (256, 1024)" fillcolor=lightblue]
	140639512251648 -> 140639248330816
	140639248330816 [label=AccumulateGrad]
	140639375793168 -> 140639375792928
	140639512251776 [label="stages.3.blocks.0.channel_mlp.fc2.bias
 (256)" fillcolor=lightblue]
	140639512251776 -> 140639375793168
	140639375793168 [label=AccumulateGrad]
	140639375792784 -> 140639375792640
	140639375792784 [label=MulBackward0]
	140639375793600 -> 140639375792784
	140639375793600 [label=DivBackward0]
	140639375793984 -> 140639375793600
	140639375793984 [label=TransposeBackward0]
	140639248510352 -> 140639375793984
	140639248510352 [label=AddBackward0]
	140639248507040 -> 140639248510352
	140639248507040 [label=UnsafeViewBackward]
	140639248548048 -> 140639248507040
	140639248548048 [label=MmBackward]
	140639248548144 -> 140639248548048
	140639248548144 [label=ViewBackward]
	140639248548288 -> 140639248548144
	140639248548288 [label=GeluBackward]
	140639248548384 -> 140639248548288
	140639248548384 [label=AddBackward0]
	140639248548480 -> 140639248548384
	140639248548480 [label=UnsafeViewBackward]
	140639248548624 -> 140639248548480
	140639248548624 [label=MmBackward]
	140639248548720 -> 140639248548624
	140639248548720 [label=ViewBackward]
	140639248548864 -> 140639248548720
	140639248548864 [label=CopyBackwards]
	140639248548960 -> 140639248548864
	140639248548960 [label=TransposeBackward0]
	140639248549056 -> 140639248548960
	140639248549056 [label=NativeLayerNormBackward]
	140639375792832 -> 140639248549056
	140639248549152 -> 140639248549056
	140639512252096 [label="stages.3.blocks.1.norm1.weight
 (256)" fillcolor=lightblue]
	140639512252096 -> 140639248549152
	140639248549152 [label=AccumulateGrad]
	140639248549104 -> 140639248549056
	140639512252224 [label="stages.3.blocks.1.norm1.bias
 (256)" fillcolor=lightblue]
	140639512252224 -> 140639248549104
	140639248549104 [label=AccumulateGrad]
	140639248548672 -> 140639248548624
	140639248548672 [label=TBackward]
	140639248549008 -> 140639248548672
	140639512322240 [label="stages.3.blocks.1.token_mlp.fc1.weight
 (256, 49)" fillcolor=lightblue]
	140639512322240 -> 140639248549008
	140639248549008 [label=AccumulateGrad]
	140639248548432 -> 140639248548384
	140639512322368 [label="stages.3.blocks.1.token_mlp.fc1.bias
 (256)" fillcolor=lightblue]
	140639512322368 -> 140639248548432
	140639248548432 [label=AccumulateGrad]
	140639248548096 -> 140639248548048
	140639248548096 [label=TBackward]
	140639248548192 -> 140639248548096
	140639512322624 [label="stages.3.blocks.1.token_mlp.fc2.weight
 (49, 256)" fillcolor=lightblue]
	140639512322624 -> 140639248548192
	140639248548192 [label=AccumulateGrad]
	140639248508720 -> 140639248510352
	140639512322752 [label="stages.3.blocks.1.token_mlp.fc2.bias
 (49)" fillcolor=lightblue]
	140639512322752 -> 140639248508720
	140639248508720 [label=AccumulateGrad]
	140639375792592 -> 140639375792544
	140639512322944 [label="stages.3.blocks.1.norm2.weight
 (256)" fillcolor=lightblue]
	140639512322944 -> 140639375792592
	140639375792592 [label=AccumulateGrad]
	140639375792256 -> 140639375792544
	140639512323072 [label="stages.3.blocks.1.norm2.bias
 (256)" fillcolor=lightblue]
	140639512323072 -> 140639375792256
	140639375792256 [label=AccumulateGrad]
	140639375792160 -> 140639375792112
	140639375792160 [label=UnsqueezeBackward0]
	140639375792496 -> 140639375792160
	140639512323328 [label="stages.3.blocks.1.connect.weight
 (256, 1, 3)" fillcolor=lightblue]
	140639512323328 -> 140639375792496
	140639375792496 [label=AccumulateGrad]
	140639375791824 -> 140639375791680
	140639375791824 [label=MulBackward0]
	140639375791920 -> 140639375791824
	140639375791920 [label=DivBackward0]
	140639375792736 -> 140639375791920
	140639375792736 [label=AddBackward0]
	140639375792304 -> 140639375792736
	140639375792304 [label=UnsafeViewBackward]
	140639248510784 -> 140639375792304
	140639248510784 [label=MmBackward]
	140639375793072 -> 140639248510784
	140639375793072 [label=ViewBackward]
	140639248548528 -> 140639375793072
	140639248548528 [label=GeluBackward]
	140639248548240 -> 140639248548528
	140639248548240 [label=AddBackward0]
	140639248549200 -> 140639248548240
	140639248549200 [label=UnsafeViewBackward]
	140639248549248 -> 140639248549200
	140639248549248 [label=MmBackward]
	140639248549344 -> 140639248549248
	140639248549344 [label=ViewBackward]
	140639248549488 -> 140639248549344
	140639248549488 [label=NativeLayerNormBackward]
	140639375791872 -> 140639248549488
	140639375792592 -> 140639248549488
	140639375792256 -> 140639248549488
	140639248549296 -> 140639248549248
	140639248549296 [label=TBackward]
	140639248549536 -> 140639248549296
	140639512323776 [label="stages.3.blocks.1.channel_mlp.fc1.weight
 (1024, 256)" fillcolor=lightblue]
	140639512323776 -> 140639248549536
	140639248549536 [label=AccumulateGrad]
	140639248548576 -> 140639248548240
	140639512323904 [label="stages.3.blocks.1.channel_mlp.fc1.bias
 (1024)" fillcolor=lightblue]
	140639512323904 -> 140639248548576
	140639248548576 [label=AccumulateGrad]
	140639248548336 -> 140639248510784
	140639248548336 [label=TBackward]
	140639248547952 -> 140639248548336
	140639512324160 [label="stages.3.blocks.1.channel_mlp.fc2.weight
 (256, 1024)" fillcolor=lightblue]
	140639512324160 -> 140639248547952
	140639248547952 [label=AccumulateGrad]
	140639375792688 -> 140639375792736
	140639512324288 [label="stages.3.blocks.1.channel_mlp.fc2.bias
 (256)" fillcolor=lightblue]
	140639512324288 -> 140639375792688
	140639375792688 [label=AccumulateGrad]
	140639375791632 -> 140639375791488
	140639512324480 [label="norm.weight
 (256)" fillcolor=lightblue]
	140639512324480 -> 140639375791632
	140639375791632 [label=AccumulateGrad]
	140639375791584 -> 140639375791488
	140639512324608 [label="norm.bias
 (256)" fillcolor=lightblue]
	140639512324608 -> 140639375791584
	140639375791584 [label=AccumulateGrad]
	140639375791296 -> 140639375791440
	140639375791296 [label=TBackward]
	140639375791776 -> 140639375791296
	140639512324736 [label="head.weight
 (1000, 256)" fillcolor=lightblue]
	140639512324736 -> 140639375791776
	140639375791776 [label=AccumulateGrad]
	140639375791152 -> 140639375737984
}
